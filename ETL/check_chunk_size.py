import json
import statistics

def analyze_chunks(filename):
    with open(filename, 'r', encoding='utf-8') as f:
        chunks = json.load(f)

    # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Å–µ–∫—Ü–∏–∏, –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–±—ã—á–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏–µ
    section_lengths = []
    oversized_chunks = []

    for chunk in chunks:
        if chunk['type'] == 'section':
            # –°—á–∏—Ç–∞–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ + –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (—Ç–∞–∫ –∫–∞–∫ loader –∏—Ö —Å–∫–ª–µ–∏–≤–∞–µ—Ç)
            # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –¥–ª–∏–Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ ~100 —Å–∏–º–≤–æ–ª–æ–≤, –Ω–æ –ª—É—á—à–µ —Å—á–∏—Ç–∞—Ç—å —á–µ—Å—Ç–Ω–æ, 
            # –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ —Ç–æ—á–Ω–æ—Å—Ç–∏, –Ω–æ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ö–≤–∞—Ç–∏—Ç –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞.
            length = len(chunk['text'])
            section_lengths.append(length)
            
            if length > 8000:
                oversized_chunks.append({
                    "id": chunk['chunk_id'],
                    "len": length,
                    "title": chunk.get('section_title', 'No Title')
                })

    if not section_lengths:
        print("–°–µ–∫—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        return

    print(f"{'='*40}")
    print(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ß–ê–ù–ö–û–í (—Ç–æ–ª—å–∫–æ type='section')")
    print(f"{'='*40}")
    print(f"–í—Å–µ–≥–æ —Å–µ–∫—Ü–∏–π:    {len(section_lengths)}")
    print(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {min(section_lengths)}")
    print(f"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞:     {int(statistics.mean(section_lengths))}")
    print(f"–ú–µ–¥–∏–∞–Ω–Ω–∞—è –¥–ª–∏–Ω–∞:   {int(statistics.median(section_lengths))}")
    print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {max(section_lengths)}")
    print(f"{'-'*40}")
    
    print(f"‚ö†Ô∏è –ß–∞–Ω–∫–∏ –¥–ª–∏–Ω–Ω–µ–µ 8000 —Å–∏–º–≤–æ–ª–æ–≤: {len(oversized_chunks)}")
    
    if oversized_chunks:
        print("\n–°–ø–∏—Å–æ–∫ '–æ–±—Ä–µ–∑–∞–Ω–Ω—ã—Ö' —á–∞–Ω–∫–æ–≤ (Top 10):")
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –æ—Ç —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö
        oversized_chunks.sort(key=lambda x: x['len'], reverse=True)
        for c in oversized_chunks[:10]:
            print(f" ‚Ä¢ {c['id']:<10} | {c['len']} —Å–∏–º–≤. | {c['title']}")

if __name__ == "__main__":
    analyze_chunks("ETL/hipaa_chunks_grouped.json")